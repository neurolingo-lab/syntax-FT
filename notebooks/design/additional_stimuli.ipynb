{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dba12a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of 7130 nouns remain to be added to the stimuli lists. 1225 adjectives remain to be added to the stimuli lists.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "\n",
    "# Load in Nina's final stimuli lists and the consonants\n",
    "stimpath = Path(\"../../word_ngrams/\").resolve()\n",
    "pnp_stim_even = pd.read_csv(stimpath / \"final_P_NP_evensubs.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "pnp_stim_odd = pd.read_csv(stimpath / \"final_P_NP_oddsubs.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "pnp_stim = pd.concat([pnp_stim_even, pnp_stim_odd]).reset_index(drop=True)\n",
    "cons = pd.read_csv(stimpath / \"cons_clust_final_candidates.csv\").set_index([\"clus1\", \"clus2\"])\n",
    "\n",
    "# Load in the core list of all words, isolate by nouns\n",
    "wordcats = pd.read_csv(stimpath / \"1grams_english_1b_with_pos.csv\").convert_dtypes()\n",
    "\n",
    "# Isolate the words which are nouns in the top 45k\n",
    "wordcats[\"word\"] = wordcats[\"ngram\"].str.split(\"_\").str[0]\n",
    "wordcats = wordcats[~wordcats[\"word\"].str.isupper()].reset_index(drop=True)\n",
    "wordcats[\"POS\"] = wordcats[\"ngram\"].str.split(\"_\").str[1]\n",
    "wordcats.drop(columns=[\"ngram\"], inplace=True)\n",
    "wordcats = wordcats.reindex(columns=[\"word\", \"POS\", \"freq\"])\n",
    "nouns = wordcats[wordcats[\"POS\"] == \"NOUN\"].reset_index(drop=True)\n",
    "nouns[\"wordlen\"] = nouns[\"word\"].str.len()\n",
    "adjs = wordcats[wordcats[\"POS\"] == \"ADJ\"].reset_index(drop=True)\n",
    "adjs[\"wordlen\"] = adjs[\"word\"].str.len()\n",
    "\n",
    "# Isolate the nouns not yet in the stimuli lists\n",
    "pnp_stim_words = pd.melt(pnp_stim[[\"w1\", \"w2\"]], ignore_index=False).reset_index(drop=False)\n",
    "remidx = ~nouns[\"word\"].isin(pnp_stim_words[\"value\"])\n",
    "adj_remidx = ~adjs[\"word\"].isin(pnp_stim_words[\"value\"])\n",
    "candidates = nouns[remidx & nouns[\"wordlen\"].isin((3, 4, 5))].reset_index(drop=True).copy()\n",
    "adj_candidates = adjs[adj_remidx & adjs[\"wordlen\"].isin((3, 4, 5))].reset_index(drop=True).copy()\n",
    "print(\n",
    "    f\"A total of {len(candidates)} nouns remain to be added to the stimuli lists.\"\n",
    "    f\" {len(adj_candidates)} adjectives remain to be added to the stimuli lists.\"\n",
    ")\n",
    "print(candidates[\"word\"].isin(pnp_stim_words[\"value\"]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721fea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8734250, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>w1</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;way other&quot;</td></tr><tr><td>&quot;way more&quot;</td></tr><tr><td>&quot;way first&quot;</td></tr><tr><td>&quot;way many&quot;</td></tr><tr><td>&quot;way own&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;way well&quot;</td></tr><tr><td>&quot;way such&quot;</td></tr><tr><td>&quot;way older&quot;</td></tr><tr><td>&quot;way moral&quot;</td></tr><tr><td>&quot;way like&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 1)\n",
       "┌───────────┐\n",
       "│ w1        │\n",
       "│ ---       │\n",
       "│ str       │\n",
       "╞═══════════╡\n",
       "│ way other │\n",
       "│ way more  │\n",
       "│ way first │\n",
       "│ way many  │\n",
       "│ way own   │\n",
       "│ …         │\n",
       "│ way well  │\n",
       "│ way such  │\n",
       "│ way older │\n",
       "│ way moral │\n",
       "│ way like  │\n",
       "└───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gerce\\AppData\\Local\\Temp\\ipykernel_453076\\2222743060.py:23: DeprecationWarning: `is_in` with a collection of the same datatype is ambiguous and deprecated.\n",
      "Please use `implode` to return to previous behavior.\n",
      "\n",
      "See https://github.com/pola-rs/polars/issues/22149 for more information.\n",
      "  goodcand = q.collect().to_pandas()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100_000, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ngram</th><th>freq</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;of the&quot;</td><td>1741529442</td></tr><tr><td>&quot;in the&quot;</td><td>1043688187</td></tr><tr><td>&quot;to the&quot;</td><td>686570630</td></tr><tr><td>&quot;on the&quot;</td><td>446536709</td></tr><tr><td>&quot;and the&quot;</td><td>446190715</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;cell adhesion&quot;</td><td>187605</td></tr><tr><td>&quot;and defence&quot;</td><td>187605</td></tr><tr><td>&quot;the testator&quot;</td><td>187603</td></tr><tr><td>&quot;suppressed by&quot;</td><td>187590</td></tr><tr><td>&quot;patiently for&quot;</td><td>187588</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100_000, 2)\n",
       "┌───────────────┬────────────┐\n",
       "│ ngram         ┆ freq       │\n",
       "│ ---           ┆ ---        │\n",
       "│ str           ┆ i64        │\n",
       "╞═══════════════╪════════════╡\n",
       "│ of the        ┆ 1741529442 │\n",
       "│ in the        ┆ 1043688187 │\n",
       "│ to the        ┆ 686570630  │\n",
       "│ on the        ┆ 446536709  │\n",
       "│ and the       ┆ 446190715  │\n",
       "│ …             ┆ …          │\n",
       "│ cell adhesion ┆ 187605     │\n",
       "│ and defence   ┆ 187605     │\n",
       "│ the testator  ┆ 187603     │\n",
       "│ suppressed by ┆ 187590     │\n",
       "│ patiently for ┆ 187588     │\n",
       "└───────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "w1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "w2",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1eb8991a-fedf-43ca-9d51-401e65b2c990",
       "rows": [
        [
         "0",
         "way",
         "more"
        ],
        [
         "1",
         "way",
         "past"
        ],
        [
         "2",
         "way",
         "more"
        ],
        [
         "3",
         "way",
         "back"
        ],
        [
         "4",
         "way",
         "round"
        ],
        [
         "5",
         "way",
         "off"
        ],
        [
         "6",
         "way",
         "over"
        ],
        [
         "7",
         "way",
         "down"
        ],
        [
         "8",
         "way",
         "out"
        ],
        [
         "9",
         "way",
         "for"
        ],
        [
         "10",
         "way",
         "home"
        ],
        [
         "11",
         "way",
         "would"
        ],
        [
         "12",
         "way",
         "than"
        ],
        [
         "13",
         "way",
         "too"
        ],
        [
         "14",
         "way",
         "with"
        ],
        [
         "15",
         "way",
         "you"
        ],
        [
         "16",
         "way",
         "past"
        ],
        [
         "17",
         "way",
         "but"
        ],
        [
         "18",
         "way",
         "but"
        ],
        [
         "19",
         "way",
         "back"
        ],
        [
         "20",
         "way",
         "out"
        ],
        [
         "21",
         "way",
         "over"
        ],
        [
         "22",
         "life",
         "more"
        ],
        [
         "23",
         "life",
         "like"
        ],
        [
         "24",
         "life",
         "more"
        ],
        [
         "25",
         "life",
         "back"
        ],
        [
         "26",
         "life",
         "out"
        ],
        [
         "27",
         "life",
         "after"
        ],
        [
         "28",
         "life",
         "story"
        ],
        [
         "29",
         "life",
         "would"
        ],
        [
         "30",
         "life",
         "again"
        ],
        [
         "31",
         "life",
         "you"
        ],
        [
         "32",
         "life",
         "like"
        ],
        [
         "33",
         "life",
         "but"
        ],
        [
         "34",
         "life",
         "but"
        ],
        [
         "35",
         "life",
         "back"
        ],
        [
         "36",
         "life",
         "may"
        ],
        [
         "37",
         "life",
         "have"
        ],
        [
         "38",
         "life",
         "may"
        ],
        [
         "39",
         "life",
         "out"
        ],
        [
         "40",
         "man",
         "like"
        ],
        [
         "41",
         "man",
         "out"
        ],
        [
         "42",
         "man",
         "would"
        ],
        [
         "43",
         "man",
         "than"
        ],
        [
         "44",
         "man",
         "with"
        ],
        [
         "45",
         "man",
         "you"
        ],
        [
         "46",
         "man",
         "like"
        ],
        [
         "47",
         "man",
         "but"
        ],
        [
         "48",
         "man",
         "but"
        ],
        [
         "49",
         "man",
         "may"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 7434
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>way</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>way</td>\n",
       "      <td>past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>way</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>way</td>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>way</td>\n",
       "      <td>round</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>wrong</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>wrong</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>wrong</td>\n",
       "      <td>side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>wrong</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>wrong</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         w1     w2\n",
       "0       way   more\n",
       "1       way   past\n",
       "2       way   more\n",
       "3       way   back\n",
       "4       way  round\n",
       "...     ...    ...\n",
       "7429  wrong    for\n",
       "7430  wrong    way\n",
       "7431  wrong   side\n",
       "7432  wrong   with\n",
       "7433  wrong  place\n",
       "\n",
       "[7434 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import interact_manual, RadioButtons\n",
    "\n",
    "\n",
    "# Convert the candidates to a polars DataFrame for faster processing\n",
    "noun_cand = pl.from_pandas(candidates[\"word\"].str.lower())\n",
    "adj_cand = pl.from_pandas(adj_candidates[\"word\"].str.lower())\n",
    "# Create a list of all possible combinations of nouns and adjectives\n",
    "pairs = noun_cand.to_frame().join(adj_cand.to_frame(), how=\"cross\")\n",
    "pairs = pairs.rename({\"word\": \"w1\", \"word_right\": \"w2\"})\n",
    "display(pairs.shape)\n",
    "\n",
    "\n",
    "# Load 2grams\n",
    "ngrams2 = pl.read_csv(stimpath / \"2grams_english_1a_no_pos.csv\")\n",
    "ngrams2.with_columns(ngram=ngrams2[\"ngram\"].str.to_lowercase())\n",
    "\n",
    "q = pairs.lazy().filter(\n",
    "    pl.concat_str(pl.col(\"w1\"), pl.col(\"w2\"), separator=\" \").is_in(ngrams2[\"ngram\"]),\n",
    "    pl.concat_str(pl.col(\"w2\"), pl.col(\"w1\"), separator=\" \").is_in(ngrams2[\"ngram\"]).not_(),\n",
    ")\n",
    "goodcand = q.collect().to_pandas()\n",
    "display(ngrams2)\n",
    "display(goodcand)\n",
    "\n",
    "goodcand.to_csv(stimpath / \"addtl_stimuli_phrase_candidates.csv\", index=False)\n",
    "print(goodcand[\"w1\"].isin(pnp_stim_words[\"value\"]).sum())\n",
    "print(goodcand[\"w2\"].isin(pnp_stim_words[\"value\"]).sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
