### Exploring intermodulation with multimodal stimuli

The paper seeks to characterize whether intermodulation frequencies can capture interactions between stimuli of different modalities. Pure-tone audio stimuli and grating visual stimuli were modulated (FM and contrast respectively) to produce frequency tags in the two domains:

![Pasted image 20250310174847](../../assets/Pasted%20image%2020250310174847.png)

Further frequency tagging was performed in the audio domain by optionally including amplitude modulation, and in the visual domain by varying the diameter of the stimulus itself:

![Pasted image 20250310175030](../../assets/Pasted%20image%2020250310175030.png)

A 3 x 2 factorial design was then used to compare (auditory, visual, audiovisual) x (single modulation, dual modulation) and see where the IM components would be observed in MEG recordings.

![Pasted image 20250310175213](../../assets/Pasted%20image%2020250310175213.png)


In general this study is quite strange and relies on many unreliable choices of statistical test and analysis method. This is compounded by the very low secondary tag frequencies used in visual stimuli (0.2 Hz width modulation). Nonetheless, that they were able to see IM responses at all in the visual data is quite remarkable:

![Pasted image 20250310175823](../../assets/Pasted%20image%2020250310175823.png)

They find no IM responses to indicate cross-modal interactions when the two sets of stimuli were observed passively and did not interact with one another in a task format.

See the full literature review workspace [Frequency Tagging Literature](../Frequency%20Tagging%20Literature.pdf) to see my comments on the detailed methodology