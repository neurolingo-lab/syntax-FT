### Semantic Wavelet-Induced Frequency Tagging

This paper gets to the core of the issue of "functional" tagging, in which a cognitive process is repeated successively with fixed interval to generate a fixed-frequency potential, and "cosmetic" tagging in which aspects of a stimulus itself such as contrast, luminance, amplitude, or frequency are directly manipulated without a substantial effect on the semantic content of the stimulus.

The paper points out that while flicker/sinusoidally-modulating visual stimuli are very good at generating tags to follow activity through the brain, the tags are notably stronger in low-level processing areas of cortex as compared to higher order areas. Visual tags are more robustly observed in occipital primary visual areas than elsewhere, and auditory tags are seen most strongly in primary visual cortex.

One notable example mentioned is that previous studies show inconsistent results when comparing the amplitude of an SSVEP between situations where a visual object is recognized and not recognized. They claim this is because both the low-level feature extraction systems (edge detection and color detection, e.g.) as well as the higher-order information systems are both tagged with functional tags.

"Semantic" tags, which we have called "functional" tags in discussion before, emerge from tagging the semantic content of a stimulus rather than the physical properties. Repeated Stimulus Visual Evoked Potentials (RSVEPs) are a good example of this, as while the content of the stimulus changes (such as changing words displayed on a screen) fundamental properties such as luminance do not change much.

The paper proposes SWIFT as a method to selectively tag the semantic contents of a display without altering the physical properties in order to selectively tag systems involved in processing semantic image content.

The method itself relies heavily on wavelet transforms of an image, which decompose the image into wavelets in 3D space, in order to selectively scramble the image while retaining low-level attributes such as edge quantity. They motivate the choice of wavelets by pointing out that other alternatievs such as the FFT do not preserve local properties and instead act on the whole stimulus.

Wavelets are found for a stimulus in the space of vertical, horizontal, and diagonal components. The stimulus is decomposed into 6 levels of wavelets of varying scales, and within each level any given point is represented by a 3D vector for the components. 

SWIFT scrambles the wavelets by creating two random vectors at each point with the same magnitude as the original stimulus, but a randomly chosen direction. The three points including the original vector then form a circle in the sphere.

The tag for SWIFT is then generated by beginning a cycling along the circle at the original image's vectors, and the speed of the cycle defines the frequency of the tag:

![Pasted image 20250310215635](../../assets/Pasted%20image%2020250310215635.png)

They note that it was necessary for some wavelets to cycle at harmonics of the base tagging frequency in order to avoid large-scale luminance changes similar to cosmetic tagging.

They used an experiment in which subject observed a SWIFT-tagged sequence with images that cohered and decohered. Subjects needed to press a button once they recognized an image as having appeared. In the first half of trials subjects did not know the images to be recognized, while the second half began with a steady non-tagged version of the stimuli to let them know what was coming. Sensor-space responses at the tagging frequency (1.5 Hz) were robust and centered on the parietal and frontal lobes:

![Pasted image 20250310220331](../../assets/Pasted%20image%2020250310220331.png)

QR trials are where the image was quickly recognized, while TR trials are slow-recognition trials (tardy) and NO indicates no recognition. 

All in all, the method is a quite elegant way to separate semantic and cosmetic features of a stimulus for the purpose of tag tracking. It is limited, however, in the frequencies it can support for tags as beyond a certain point the image will cycle too fast for clear perception of the stimulus I think.

See [Gordon et al 2017](Gordon%20et%20al%202017.md) for a use of the method in conjunction with cosmetic tags that is quite nice.