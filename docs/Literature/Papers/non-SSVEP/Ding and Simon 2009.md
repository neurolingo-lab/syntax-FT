### Auditory modulation elicits SSR

Ding and Simon explored different methods of modulating auditory stimuli to evoke response and intermodulation components.

Stimuli were both frequency modulated ($\mathbf{f}_{FM} = 40 \; \text{Hz}$) and amplitude modulated ($\mathbf{f}_{AM} < 15 \; \text{Hz}$) during presentation, and subject neural activity was recorded in MEG to observe SSR results.

The authors note that while slow modulations below 20 Hz are well-studied and have been shown to entrain activity **in single neurons** via phase locking (citing Drullman et al. 1994, Poeppel et al. 2003, Channon et al. 1995) at higher frequencies above this cutoff the activity loses phase-locked properties and seems to use a rate code to represented the stimulus fluctuations (Bendor and Wang 2007). **Note that this is for single-unit recordings**.

Fast modulations at ~40 Hz are also well-studied as they evoke strong MEG and EEG responses and are important in speech perception.

In MEG phase-locking is noted to occur up to and possibly beyond 80 Hz tags, thanks to population averaging within a sensor. In fact IM frequencies for similar-frequency AM and FM tags appear during integration. However dissimilar-frequency tags have not been examined and play an important role in speech perception.

Pure-tone stimuli were FM-tagged at a fixed 37.7 Hz frequency, and AM-tagged at 0.3, 0.7, 1.7, 3.1, 4.9, 9.0, and 13.8 Hz. 

Ding and Simon found that the power but not phase-locking of both the AM and FM tags decreased as $\mathbf{f}_{AM}$ increased. The response at $\mathbf{f}_{FM}$ was found to be modulated in both amplitude and phase at $\mathbf{f}_{AM}$, showing a tight interdependence on the frequency responses to both stimuli. 

I stopped here since I didn't want to get into the guts of aSSR mechanics, but good to back to this if/when we approach audio.